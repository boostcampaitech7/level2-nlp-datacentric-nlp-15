{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('')\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 예측 확률 얻기 함수\n",
    "def get_predictions(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            probs = softmax(outputs.logits)\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# 텍스트 품질 검사 함수\n",
    "def check_text_quality(text):\n",
    "    # 아스키코드나 특수문자 비율 계산\n",
    "    special_chars = len(re.findall(r'[^\\w\\s가-힣]', text))\n",
    "    total_chars = len(text)\n",
    "    special_char_ratio = special_chars / total_chars if total_chars > 0 else 1\n",
    "    \n",
    "    # 한글 비율 계산\n",
    "    korean_chars = len(re.findall(r'[가-힣]', text))\n",
    "    korean_ratio = korean_chars / total_chars if total_chars > 0 else 0\n",
    "    \n",
    "    return special_char_ratio, korean_ratio\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=7)\n",
    "\n",
    "# 데이터셋 준비\n",
    "text_dataset = TextDataset(df['text'].tolist(), df['target'].tolist(), tokenizer)\n",
    "dataloader = DataLoader(text_dataset, batch_size=32)\n",
    "\n",
    "# GPU 사용 가능시 사용\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률 얻기\n",
    "pred_probs = get_predictions(model, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 품질 분석\n",
    "quality_scores = []\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    special_ratio, korean_ratio = check_text_quality(text)\n",
    "    max_prob = np.max(pred_probs[idx])\n",
    "    \n",
    "    # 품질 점수 계산 (낮을수록 제거 대상)\n",
    "    quality_score = (\n",
    "        (1 - special_ratio) * 0.3 +  # 특수문자 비율이 낮을수록 좋음\n",
    "        korean_ratio * 0.6 +         # 한글 비율이 높을수록 좋음\n",
    "        max_prob * 0.1               # 예측 신뢰도가 높을수록 좋음\n",
    "    )\n",
    "    \n",
    "    quality_scores.append({\n",
    "        'index': idx,\n",
    "        'text': text,\n",
    "        'special_ratio': special_ratio,\n",
    "        'korean_ratio': korean_ratio,\n",
    "        'prediction_confidence': max_prob,\n",
    "        'quality_score': quality_score\n",
    "    })\n",
    "\n",
    "# 품질 점수를 데이터프레임으로 변환\n",
    "quality_df = pd.DataFrame(quality_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n품질 점수 0.50 이하인 데이터:\")\n",
    "very_low_quality = quality_df[quality_df['quality_score'] <= 0.50]\n",
    "print(f\"총 {len(very_low_quality)}개 발견\")\n",
    "\n",
    "print(\"\\n샘플 :\")\n",
    "for _, row in very_low_quality.head(239).iterrows():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"텍스트: {row['text']}\")\n",
    "    print(f\"특수문자 비율: {row['special_ratio']:.3f}\")\n",
    "    print(f\"한글 비율: {row['korean_ratio']:.3f}\")\n",
    "    print(f\"예측 신뢰도: {row['prediction_confidence']:.3f}\")\n",
    "    print(f\"품질 점수: {row['quality_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품질 점수가 0.5 이하인 데이터의 인덱스 확인\n",
    "low_quality_indices = quality_df[quality_df['quality_score'] <= 0.5]['index'].values\n",
    "print(f\"제거할 데이터 수: {len(low_quality_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터에서 해당 인덱스를 제외한 데이터만 선택\n",
    "clean_df = df.drop(index=low_quality_indices)\n",
    "print(f\"정제된 데이터 수: {len(clean_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정제된 데이터의 라벨 분포 확인\n",
    "print(\"\\n정제된 데이터의 라벨 분포:\")\n",
    "print(clean_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "clean_df['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "clean_df.to_csv('', index=False)\n",
    "print(\"데이터 정제 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Conda base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
